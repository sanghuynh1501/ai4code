{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "BERT_MODEL_PATH = 'microsoft/codebert-base'\n",
    "MARK_PATH = 'weights/model_markdown_07840.pth'\n",
    "CODE_PATH = 'weights/model_code.pth'\n",
    "CODE_MARK_PATH = 'weights/model_code_mark_07575.pth'\n",
    "CODE_MARK_RANK_PATH = 'weights/model_code_mark_rank.pth'\n",
    "SIGMOID_PATH = 'weights/model_sigmoid_83959.pth'\n",
    "FASTTEST_MODEL = 'weights/model140000.bin'\n",
    "DATA_DIR = Path('AI4Code')\n",
    "LABELS = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'k',\n",
    "          'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "MAX_TREE_DEPTH = 8\n",
    "TREE_METHOD = 'gpu_hist'\n",
    "SUBSAMPLE = 0.6\n",
    "REGULARIZATION = 0.1\n",
    "GAMMA = 0.3\n",
    "POS_WEIGHT = 1\n",
    "EARLY_STOP = 50\n",
    "LEARNING_RATE = 0.01\n",
    "NUM_TRAIN = 200\n",
    "RANK_COUNT = 20\n",
    "SIGMOID_RANK_COUNT = 10\n",
    "MD_MAX_LEN = 64\n",
    "CODE_MAX_LEN = 23\n",
    "TOTAL_MAX_LEN = 512\n",
    "MAX_LEN = 128\n",
    "NVALID = 0.1\n",
    "EPOCH = 5\n",
    "BS = 2\n",
    "NW = 0\n",
    "RANKS = [i for i in range(0, RANK_COUNT + 1, 1)]\n",
    "accumulation_steps = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sang/anaconda3/envs/ai4code_new/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "class MarkdownOnlyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MarkdownOnlyModel, self).__init__()\n",
    "        self.distill_bert = AutoModel.from_pretrained(BERT_MODEL_PATH)\n",
    "        self.top = nn.Linear(768, 1)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        x = self.distill_bert(ids, mask)[0]\n",
    "        x = self.top(x[:, 0, :])\n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class MarkdownRankModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MarkdownRankModel, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(BERT_MODEL_PATH)\n",
    "        self.top = nn.Linear(770, len(RANKS))\n",
    "        self.activation = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, ids, mask, fts, code_lens):\n",
    "        x = self.model(ids, mask)[0]\n",
    "        x = torch.cat((x[:, 0, :], fts, code_lens), 1)\n",
    "\n",
    "        x = self.top(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class SigMoidModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SigMoidModel, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(BERT_MODEL_PATH)\n",
    "        self.top = nn.Linear(770, 1)\n",
    "\n",
    "    def forward(self, ids, mask, fts, code_lens):\n",
    "        x = self.model(ids, mask)[0]\n",
    "        x = torch.cat((x[:, 0, :], fts, code_lens), 1)\n",
    "        x = self.top(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/sang/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/sang/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "from bisect import bisect\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "from config import LABELS, RANK_COUNT, RANKS\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "stemmer = WordNetLemmatizer()\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "\n",
    "def id_to_label(ids):\n",
    "    return [LABELS.index(s) for s in ids]\n",
    "\n",
    "\n",
    "def label_to_id(labels):\n",
    "    return ''.join([LABELS[i] for i in labels])\n",
    "\n",
    "\n",
    "def preprocess_text(document):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(document))\n",
    "\n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "\n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    # return document\n",
    "\n",
    "    # Lemmatization\n",
    "    tokens = document.split()\n",
    "    tokens = [stemmer.lemmatize(word) for word in tokens]\n",
    "    tokens = [word for word in tokens if len(word) > 3]\n",
    "\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text\n",
    "\n",
    "\n",
    "def preprocess_code(cell):\n",
    "    return str(cell).replace('\\\\n', '\\n')[:200]\n",
    "\n",
    "\n",
    "def read_notebook(path):\n",
    "    return (\n",
    "        pd.read_json(\n",
    "            path,\n",
    "            dtype={'cell_type': 'category', 'source': 'str'})\n",
    "        .assign(id=path.stem)\n",
    "        .rename_axis('cell_id')\n",
    "    )\n",
    "\n",
    "\n",
    "def get_features_mark(df, mode='train'):\n",
    "\n",
    "    features = []\n",
    "    df = df.sort_values('rank').reset_index(drop=True)\n",
    "\n",
    "    for _, sub_df in tqdm(df.groupby('id')):\n",
    "\n",
    "        mark_sub_df_all = sub_df[sub_df.cell_type == 'markdown']\n",
    "\n",
    "        for i in range(0, mark_sub_df_all.shape[0]):\n",
    "            mark = mark_sub_df_all.iloc[i]['cell_id']\n",
    "            pct_rank = mark_sub_df_all.iloc[i]['pct_rank']\n",
    "\n",
    "            feature = {\n",
    "                'mark': mark,\n",
    "                'pct_rank': pct_rank\n",
    "            }\n",
    "\n",
    "            features.append(feature)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_features_rank(df, mode='train'):\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "    code_ranks = []\n",
    "    df = df.sort_values('rank').reset_index(drop=True)\n",
    "\n",
    "    for id, sub_df in tqdm(df.groupby('id')):\n",
    "\n",
    "        mark_sub_df_all = sub_df[sub_df.cell_type == 'markdown']\n",
    "        code_sub_df_all = sub_df[sub_df.cell_type == 'code']\n",
    "        total_code_len = len(code_sub_df_all)\n",
    "        total_md = mark_sub_df_all.shape[0]\n",
    "\n",
    "        for i in range(0, mark_sub_df_all.shape[0]):\n",
    "            for j in range(0, code_sub_df_all.shape[0], RANK_COUNT):\n",
    "                code_sub_df = code_sub_df_all[j: j + RANK_COUNT]\n",
    "\n",
    "                codes = code_sub_df['cell_id'].to_list()\n",
    "                ranks = code_sub_df['rank'].values\n",
    "                total_code = code_sub_df.shape[0]\n",
    "\n",
    "                mark = mark_sub_df_all.iloc[i]['cell_id']\n",
    "                rank = mark_sub_df_all.iloc[i]['rank']\n",
    "\n",
    "                min_rank = 0 if j == 0 else ranks[0]\n",
    "                max_rank = ranks[-1]\n",
    "\n",
    "                relative = 1\n",
    "\n",
    "                if total_code_len - j <= RANK_COUNT and rank > min_rank:\n",
    "                    relative = 1\n",
    "                else:\n",
    "                    if rank < min_rank or rank > max_rank:\n",
    "                        relative = 0\n",
    "\n",
    "                code_rank = 0\n",
    "                if relative == 1:\n",
    "                    if j == 0 and rank < ranks[0]:\n",
    "                        code_rank = 0\n",
    "                    else:\n",
    "                        sub_ranks = rank - ranks\n",
    "                        sub_ranks[sub_ranks < 0] = 100000\n",
    "                        code_rank = np.argmin(sub_ranks) + 1\n",
    "\n",
    "                if len(ranks) < RANK_COUNT:\n",
    "                    ranks = np.concatenate(\n",
    "                        [ranks, np.ones(RANK_COUNT - len(ranks),) * ranks[-1]], 0)\n",
    "\n",
    "                if mode == 'classification':\n",
    "                    if relative == 1:\n",
    "                        feature = {\n",
    "                            'id': id,\n",
    "                            'total_code': int(total_code),\n",
    "                            'total_md': int(total_md),\n",
    "                            'codes': codes,\n",
    "                            'ranks': ranks,\n",
    "                            'code_rank': code_rank,\n",
    "                            'mark': mark,\n",
    "                            'pct_rank': mark_sub_df_all.iloc[i]['pct_rank'],\n",
    "                            'relative': relative,\n",
    "                            'total_code_len': total_code_len\n",
    "                        }\n",
    "                        features.append(feature)\n",
    "                elif mode == 'sigmoid':\n",
    "                    if total_code_len > RANK_COUNT:\n",
    "                        feature = {\n",
    "                            'total_code': int(total_code),\n",
    "                            'total_md': int(total_md),\n",
    "                            'codes': codes,\n",
    "                            'ranks': ranks,\n",
    "                            'code_rank': code_rank,\n",
    "                            'mark': mark,\n",
    "                            'pct_rank': mark_sub_df_all.iloc[i]['pct_rank'],\n",
    "                            'relative': relative,\n",
    "                            'total_code_len': total_code_len\n",
    "                        }\n",
    "                        features.append(feature)\n",
    "                else:\n",
    "                    feature = {\n",
    "                        'total_code': int(total_code),\n",
    "                        'total_md': int(total_md),\n",
    "                        'codes': codes,\n",
    "                        'ranks': ranks,\n",
    "                        'code_rank': code_rank,\n",
    "                        'mark': mark,\n",
    "                        'pct_rank': mark_sub_df_all.iloc[i]['pct_rank'],\n",
    "                        'relative': relative,\n",
    "                        'total_code_len': total_code_len\n",
    "                    }\n",
    "                    features.append(feature)\n",
    "                labels.append(relative)\n",
    "                code_ranks.append(code_rank)\n",
    "\n",
    "    return np.array(features), np.array(labels), np.array(code_ranks)\n",
    "\n",
    "\n",
    "def validate_markdown(model, val_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    tbar = tqdm(val_loader, file=sys.stdout)\n",
    "\n",
    "    preds = []\n",
    "    mark_ids = []\n",
    "    mark_hash = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (ids, mask, _, id) in enumerate(tbar):\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred = model(ids.to(device), mask.to(device))\n",
    "            preds += pred.detach().cpu().numpy().ravel().tolist()\n",
    "            mark_ids += [label_to_id(i) for i in id]\n",
    "\n",
    "    for mark, score in zip(mark_ids, preds):\n",
    "        mark_hash[mark] = score\n",
    "\n",
    "    return mark_hash\n",
    "\n",
    "\n",
    "def validate_sigmoid(model, val_loader, device, threshold=0.5):\n",
    "    model.eval()\n",
    "\n",
    "    tbar = tqdm(val_loader, file=sys.stdout)\n",
    "\n",
    "    total = 0\n",
    "    zero_total = 0\n",
    "    one_total = 0\n",
    "\n",
    "    total_true = 0\n",
    "    total_zero_true = 0\n",
    "    total_one_true = 0\n",
    "    relatives = []\n",
    "\n",
    "    preds = []\n",
    "    targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (ids, mask, fts, _, code_lens, _, target, total_code_lens) in enumerate(tbar):\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred = model(ids.to(device), mask.to(device),\n",
    "                             fts.to(device), code_lens.to(device))\n",
    "\n",
    "            code_lens = (total_code_lens.detach().cpu().numpy().ravel()\n",
    "                         <= RANK_COUNT).astype(np.int8)\n",
    "            code_len_indexs = np.nonzero(code_lens == 1)[0]\n",
    "\n",
    "            pred = torch.sigmoid(pred)\n",
    "            pred = pred.detach().cpu().numpy().ravel()\n",
    "            pred[code_len_indexs] = 1.0\n",
    "            preds += pred.tolist()\n",
    "\n",
    "            # pred = (pred >= threshold).astype(np.int8)\n",
    "            # pred = (pred | code_lens).astype(np.int8)\n",
    "            # pred = pred + code_lens\n",
    "            # pred = np.clip(pred, 0, 1)\n",
    "            relatives += pred.tolist()\n",
    "\n",
    "            target = target.detach().cpu().numpy().ravel()\n",
    "            targets += target.tolist()\n",
    "\n",
    "            zero_indexes = np.nonzero(target == 0)[0]\n",
    "            one_indexes = np.nonzero(target == 1)[0]\n",
    "\n",
    "            zero_target = target[zero_indexes]\n",
    "            one_target = target[one_indexes]\n",
    "\n",
    "            zero_pred = pred[zero_indexes]\n",
    "            one_pred = pred[one_indexes]\n",
    "\n",
    "            zero_total += len(zero_target)\n",
    "            one_total += len(one_target)\n",
    "            total += len(target)\n",
    "\n",
    "            total_zero_true += np.sum((zero_pred ==\n",
    "                                       zero_target).astype(np.int8))\n",
    "            total_one_true += np.sum((one_pred == one_target).astype(np.int8))\n",
    "            total_true += np.sum((pred == target).astype(np.int8))\n",
    "\n",
    "    return total_true / total, total_zero_true / zero_total, total_one_true / one_total, relatives, targets, preds\n",
    "\n",
    "\n",
    "def validate_rank_inference(model, val_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    tbar = tqdm(val_loader, file=sys.stdout)\n",
    "\n",
    "    preds = []\n",
    "    targets = []\n",
    "    mark_ids = []\n",
    "    mark_dict = {}\n",
    "    rank_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, (ids, mask, fts, code_len, target, cell_id, ranks) in enumerate(tbar):\n",
    "            ranks = ranks.detach().cpu().numpy().tolist()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred = model(ids.to(device), mask.to(device),\n",
    "                             fts.to(device), code_len.to(device))\n",
    "            pred = torch.argmax(pred, dim=1)\n",
    "            preds.append(pred.detach().cpu().numpy().ravel())\n",
    "            targets.append(target.detach().cpu().numpy().ravel())\n",
    "            mark_ids += [label_to_id(i) for i in cell_id]\n",
    "            rank_list += ranks\n",
    "\n",
    "    preds, targets = np.concatenate(preds), np.concatenate(targets)\n",
    "\n",
    "    for (id, pred, rank) in zip(mark_ids, preds, rank_list):\n",
    "        if pred == 0:\n",
    "            mark_dict[id] = -0.1\n",
    "        else:\n",
    "            mark_dict[id] = rank[pred - 1] + 0.1\n",
    "\n",
    "    return preds, targets, accuracy_score(targets, preds), mark_dict\n",
    "\n",
    "\n",
    "def validate_rank(model, val_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    tbar = tqdm(val_loader, file=sys.stdout)\n",
    "\n",
    "    preds = []\n",
    "    targets = []\n",
    "    code_lens = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (ids, mask, fts, _, code_len, target, _, total_code_len) in enumerate(tbar):\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred = model(ids.to(device), mask.to(device),\n",
    "                             fts.to(device), code_len.to(device))\n",
    "            pred = torch.argmax(pred, dim=1)\n",
    "            preds.append(pred.detach().cpu().numpy().ravel())\n",
    "            targets.append(target.detach().cpu().numpy().ravel())\n",
    "            code_lens.append(total_code_len.detach().cpu().numpy().ravel())\n",
    "\n",
    "    preds, targets, code_lens = np.concatenate(\n",
    "        preds), np.concatenate(targets), np.concatenate(code_lens)\n",
    "\n",
    "    return preds, targets, 0\n",
    "\n",
    "\n",
    "def count_inversions(a):\n",
    "    inversions = 0\n",
    "    sorted_so_far = []\n",
    "    for i, u in enumerate(a):  # O(N)\n",
    "        j = bisect(sorted_so_far, u)  # O(log N)\n",
    "        inversions += i - j\n",
    "        sorted_so_far.insert(j, u)  # O(N)\n",
    "    return inversions\n",
    "\n",
    "\n",
    "def kendall_tau(ground_truth, predictions):\n",
    "    total_inversions = 0  # total inversions in predicted ranks across all instances\n",
    "    total_2max = 0  # maximum possible inversions across all instances\n",
    "    for gt, pred in zip(ground_truth, predictions):\n",
    "        # rank predicted order in terms of ground truth\n",
    "        ranks = [gt.index(x) for x in pred]\n",
    "        total_inversions += count_inversions(ranks)\n",
    "        n = len(gt)\n",
    "        total_2max += n * (n - 1)\n",
    "    return 1 - 4 * total_inversions / total_2max\n",
    "\n",
    "\n",
    "def cal_kendall_tau_inference(df, mark_dict, final_pred, df_orders):\n",
    "    df.loc[df['cell_type'] == 'code',\n",
    "           'pred'] = df[df.cell_type == 'code']['rank']\n",
    "\n",
    "    # marks = df.loc[df['cell_type'] == 'markdown']['cell_id'].to_list()\n",
    "    # for mark in marks:\n",
    "    #     if mark not in final_pred:\n",
    "    #         final_pred[mark] = mark_dict[mark]\n",
    "\n",
    "    pred = []\n",
    "    cell_ids = []\n",
    "    for cell_id in final_pred.keys():\n",
    "        cell_ids.append(cell_id)\n",
    "        pred.append(final_pred[cell_id])\n",
    "\n",
    "    df_markdown_pred = pd.DataFrame(list(zip(cell_ids, pred)), columns=[\n",
    "                                    'cell_id', 'markdown_pred'])\n",
    "    df = df.merge(df_markdown_pred, on=['cell_id'], how='outer')\n",
    "\n",
    "    df.loc[df['cell_type'] == 'markdown',\n",
    "           'pred'] = df.loc[df['cell_type'] == 'markdown']['markdown_pred']\n",
    "\n",
    "    df[['id', 'cell_id', 'cell_type', 'rank', 'pred']].to_csv('predict.csv')\n",
    "    y_dummy = df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n",
    "    print(\"Preds score\", kendall_tau(df_orders.loc[y_dummy.index], y_dummy))\n",
    "\n",
    "\n",
    "def cal_kendall_tau_rank(df, pred, mark_dict, relative, df_orders):\n",
    "    index = 0\n",
    "    df = df.sort_values('rank').reset_index(drop=True)\n",
    "    df.loc[df['cell_type'] == 'code',\n",
    "           'pred'] = df[df.cell_type == 'code']['rank']\n",
    "\n",
    "    final_pred = {}\n",
    "\n",
    "    for _, sub_df in tqdm(df.groupby('id')):\n",
    "\n",
    "        mark_sub_df_all = sub_df[sub_df.cell_type == 'markdown']\n",
    "        code_sub_df_all = sub_df[sub_df.cell_type == 'code']\n",
    "\n",
    "        for i in range(0, mark_sub_df_all.shape[0]):\n",
    "            max_score = 0\n",
    "            max_index = 0\n",
    "            max_j = 0\n",
    "            for j in range(0, code_sub_df_all.shape[0], RANK_COUNT):\n",
    "                if relative[index] >= max_score:\n",
    "                    max_score = relative[index]\n",
    "                    max_index = index\n",
    "                    max_j = j\n",
    "                index += 1\n",
    "            cell_id = mark_sub_df_all.iloc[i]['cell_id']\n",
    "            if RANKS[pred[max_index]] == 0:\n",
    "                final_pred[cell_id] = -10\n",
    "            else:\n",
    "                rank_index = RANKS[pred[max_index]] - 1\n",
    "                code_sub_df = code_sub_df_all[max_j: max_j + RANK_COUNT]\n",
    "                if rank_index < code_sub_df.shape[0]:\n",
    "                    final_pred[cell_id] = code_sub_df.iloc[rank_index]['rank'] + 0.1\n",
    "                else:\n",
    "                    final_pred[cell_id] = code_sub_df.iloc[-1]['rank'] + 0.1\n",
    "\n",
    "    for _, sub_df in tqdm(df.groupby('id')):\n",
    "        mark_sub_df_all = sub_df[sub_df.cell_type == 'markdown']\n",
    "        cell_ids = mark_sub_df_all['cell_id'].to_list()\n",
    "        \n",
    "\n",
    "        # print('========================================')\n",
    "        # print('before ')\n",
    "\n",
    "        # cell_ids.sort(key=lambda id: final_pred[id])\n",
    "        # preds = []\n",
    "        # for i in range(len(cell_ids)):\n",
    "        #     preds.append(final_pred[cell_ids[i]])\n",
    "\n",
    "        # print(preds)\n",
    "\n",
    "        # preds = []\n",
    "        for i in range(len(cell_ids) - 1):\n",
    "            if final_pred[cell_ids[i]] == final_pred[cell_ids[i + 1]]:\n",
    "                equal_list = [cell_ids[i]]\n",
    "                for j in range(i + 1, len(cell_ids)):\n",
    "                    if final_pred[cell_ids[j]] == final_pred[cell_ids[i]]:\n",
    "                        equal_list.append(cell_ids[j])\n",
    "                equal_list.sort(key=lambda id: mark_dict[id])\n",
    "                for i, id in enumerate(equal_list):\n",
    "                    final_pred[id] += i / 10\n",
    "\n",
    "        # print('after ')\n",
    "\n",
    "        # cell_ids.sort(key=lambda id: final_pred[id])\n",
    "        # preds = []\n",
    "        # marks = []\n",
    "        # for i in range(len(cell_ids)):\n",
    "        #     preds.append(final_pred[cell_ids[i]])\n",
    "        #     marks.append(mark_dict[cell_ids[i]])\n",
    "\n",
    "        # print(preds)\n",
    "        # print(marks)\n",
    "\n",
    "    pred = []\n",
    "    cell_ids = []\n",
    "    for cell_id in final_pred.keys():\n",
    "        cell_ids.append(cell_id)\n",
    "        pred.append(final_pred[cell_id])\n",
    "\n",
    "    df_markdown_pred = pd.DataFrame(list(zip(cell_ids, pred)), columns=[\n",
    "                                    'cell_id', 'markdown_pred'])\n",
    "    df = df.merge(df_markdown_pred, on=['cell_id'], how='outer')\n",
    "\n",
    "    df.loc[df['cell_type'] == 'markdown',\n",
    "           'pred'] = df.loc[df['cell_type'] == 'markdown']['markdown_pred']\n",
    "\n",
    "    df[['id', 'cell_id', 'cell_type', 'rank', 'pred']].to_csv('predict.csv')\n",
    "    y_dummy = df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n",
    "    return kendall_tau(df_orders.loc[y_dummy.index], y_dummy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "class MarkdownRankDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dict_cellid_source, total_max_len, md_max_len, fts):\n",
    "        super().__init__()\n",
    "        self.dict_cellid_source = dict_cellid_source\n",
    "        self.md_max_len = md_max_len\n",
    "        self.total_max_len = total_max_len  # maxlen allowed by model config\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_PATH)\n",
    "        self.fts = fts\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.fts[index]\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            self.dict_cellid_source[row['mark']],\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.md_max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        codes = row['codes']\n",
    "        code_inputs = self.tokenizer.batch_encode_plus(\n",
    "            [str(self.dict_cellid_source[x]) for x in codes],\n",
    "            add_special_tokens=True,\n",
    "            max_length=CODE_MAX_LEN,\n",
    "            padding='max_length',\n",
    "            truncation=True\n",
    "        )\n",
    "        n_md = row['total_md']\n",
    "        n_code = row['total_code']\n",
    "        if n_md + n_code == 0:\n",
    "            fts = torch.FloatTensor([0])\n",
    "        else:\n",
    "            fts = torch.FloatTensor([n_md / (n_md + n_code)])\n",
    "\n",
    "        ids = inputs['input_ids']\n",
    "        for x in code_inputs['input_ids']:\n",
    "            ids.extend(x[:-1])\n",
    "        ids = ids[:self.total_max_len]\n",
    "        if len(ids) != self.total_max_len:\n",
    "            ids = ids + [self.tokenizer.pad_token_id, ] * \\\n",
    "                (self.total_max_len - len(ids))\n",
    "        ids = torch.LongTensor(ids)\n",
    "\n",
    "        mask = inputs['attention_mask']\n",
    "        for x in code_inputs['attention_mask']:\n",
    "            mask.extend(x[:-1])\n",
    "        mask = mask[:self.total_max_len]\n",
    "        if len(mask) != self.total_max_len:\n",
    "            mask = mask + [self.tokenizer.pad_token_id, ] * \\\n",
    "                (self.total_max_len - len(mask))\n",
    "        mask = torch.LongTensor(mask)\n",
    "\n",
    "        label = row['code_rank']\n",
    "\n",
    "        assert len(ids) == self.total_max_len\n",
    "\n",
    "        return ids, mask, fts, torch.FloatTensor([len(codes) / RANK_COUNT]), torch.LongTensor([label])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fts)\n",
    "\n",
    "\n",
    "class MarkdownOnlyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, fts, dict_cellid_source, max_len):\n",
    "        super().__init__()\n",
    "        self.dict_cellid_source = dict_cellid_source\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_PATH)\n",
    "        self.fts = fts\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.fts[index]\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            self.dict_cellid_source[row['mark']],\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = torch.LongTensor(inputs['input_ids'])\n",
    "        mask = torch.LongTensor(inputs['attention_mask'])\n",
    "\n",
    "        return ids, mask, torch.FloatTensor([row['pct_rank']]), torch.LongTensor(id_to_label(row['mark']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fts)\n",
    "\n",
    "\n",
    "class MarkdownRankNewDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dict_cellid_source, total_max_len, md_max_len, fts):\n",
    "        super().__init__()\n",
    "        self.dict_cellid_source = dict_cellid_source\n",
    "        self.md_max_len = md_max_len\n",
    "        self.total_max_len = total_max_len  # maxlen allowed by model config\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_PATH)\n",
    "        self.fts = fts\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.fts[index]\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            self.dict_cellid_source[row['mark']],\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.md_max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        codes = row['codes']\n",
    "        ranks = row['ranks']\n",
    "        code_inputs = self.tokenizer.batch_encode_plus(\n",
    "            [str(self.dict_cellid_source[x]) for x in codes],\n",
    "            add_special_tokens=True,\n",
    "            max_length=CODE_MAX_LEN,\n",
    "            padding='max_length',\n",
    "            truncation=True\n",
    "        )\n",
    "        n_md = row['total_md']\n",
    "        n_code = row['total_code']\n",
    "        if n_md + n_code == 0:\n",
    "            fts = torch.FloatTensor([0])\n",
    "        else:\n",
    "            fts = torch.FloatTensor([n_md / (n_md + n_code)])\n",
    "\n",
    "        ids = inputs['input_ids']\n",
    "        for x in code_inputs['input_ids']:\n",
    "            ids.extend(x[:-1])\n",
    "        ids = ids[:self.total_max_len]\n",
    "        if len(ids) != self.total_max_len:\n",
    "            ids = ids + [self.tokenizer.pad_token_id, ] * \\\n",
    "                (self.total_max_len - len(ids))\n",
    "        ids = torch.LongTensor(ids)\n",
    "\n",
    "        mask = inputs['attention_mask']\n",
    "        for x in code_inputs['attention_mask']:\n",
    "            mask.extend(x[:-1])\n",
    "        mask = mask[:self.total_max_len]\n",
    "        if len(mask) != self.total_max_len:\n",
    "            mask = mask + [self.tokenizer.pad_token_id, ] * \\\n",
    "                (self.total_max_len - len(mask))\n",
    "        mask = torch.LongTensor(mask)\n",
    "\n",
    "        label = row['code_rank']\n",
    "\n",
    "        assert len(ids) == self.total_max_len\n",
    "\n",
    "        return ids, mask, fts, torch.FloatTensor([len(codes) / RANK_COUNT]), torch.LongTensor([label]), torch.LongTensor(id_to_label(row['mark'])), torch.LongTensor(ranks)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fts)\n",
    "\n",
    "\n",
    "class SigMoidDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dict_cellid_source, total_max_len, md_max_len, fts):\n",
    "        super().__init__()\n",
    "        self.dict_cellid_source = dict_cellid_source\n",
    "        self.md_max_len = md_max_len\n",
    "        self.total_max_len = total_max_len  # maxlen allowed by model config\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_PATH)\n",
    "        self.fts = fts\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.fts[index]\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            self.dict_cellid_source[row['mark']],\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.md_max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        codes = row['codes']\n",
    "        code_inputs = self.tokenizer.batch_encode_plus(\n",
    "            [str(self.dict_cellid_source[x]) for x in codes],\n",
    "            add_special_tokens=True,\n",
    "            max_length=CODE_MAX_LEN,\n",
    "            padding='max_length',\n",
    "            truncation=True\n",
    "        )\n",
    "        n_md = row['total_md']\n",
    "        n_code = row['total_code']\n",
    "        if n_md + n_code == 0:\n",
    "            fts = torch.FloatTensor([0])\n",
    "        else:\n",
    "            fts = torch.FloatTensor([n_md / (n_md + n_code)])\n",
    "\n",
    "        ids = inputs['input_ids']\n",
    "        for x in code_inputs['input_ids']:\n",
    "            ids.extend(x[:-1])\n",
    "        ids = ids[:self.total_max_len]\n",
    "        if len(ids) != self.total_max_len:\n",
    "            ids = ids + [self.tokenizer.pad_token_id, ] * \\\n",
    "                (self.total_max_len - len(ids))\n",
    "        ids = torch.LongTensor(ids)\n",
    "\n",
    "        mask = inputs['attention_mask']\n",
    "        for x in code_inputs['attention_mask']:\n",
    "            mask.extend(x[:-1])\n",
    "        mask = mask[:self.total_max_len]\n",
    "        if len(mask) != self.total_max_len:\n",
    "            mask = mask + [self.tokenizer.pad_token_id, ] * \\\n",
    "                (self.total_max_len - len(mask))\n",
    "        mask = torch.LongTensor(mask)\n",
    "\n",
    "        label = row['pct_rank']\n",
    "        relative = row['relative']\n",
    "        total_code_len = row['total_code_len']\n",
    "\n",
    "        loss_mask = torch.ones(RANK_COUNT + 1,)\n",
    "        loss_mask[:len(codes) + 1] = 0\n",
    "        loss_mask = loss_mask.type(torch.ByteTensor)\n",
    "\n",
    "        assert len(ids) == self.total_max_len\n",
    "\n",
    "        return ids, mask, fts, loss_mask, torch.FloatTensor([len(codes) / RANK_COUNT]), torch.FloatTensor([label]), torch.FloatTensor([relative]), torch.FloatTensor([total_code_len])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 74.45it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 368.90it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2772913/1021269218.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m val_ds = SigMoidDataset(dict_cellid_source, md_max_len=MD_MAX_LEN,\n\u001b[0;32m---> 72\u001b[0;31m                         total_max_len=512, fts=val_fts)\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0mval_ds_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMarkdownOnlyDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_fts_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_cellid_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2772913/471512788.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dict_cellid_source, total_max_len, md_max_len, fts)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmd_max_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmd_max_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_max_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_max_len\u001b[0m  \u001b[0;31m# maxlen allowed by model config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBERT_MODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4code_new/lib/python3.7/site-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0mtokenizer_class_py\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTOKENIZER_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muse_fast\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4code_new/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1729\u001b[0m                         \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1730\u001b[0m                         \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1731\u001b[0;31m                         \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1732\u001b[0m                     )\n\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4code_new/lib/python3.7/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         )\n\u001b[1;32m    292\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4code_new/lib/python3.7/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m             \u001b[0m_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0metag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X-Linked-Etag\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ETag\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4code_new/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mhead\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'head'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4code_new/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4code_new/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    527\u001b[0m         }\n\u001b[1;32m    528\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4code_new/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4code_new/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m                 )\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4code_new/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m             )\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4code_new/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4code_new/lib/python3.7/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4code_new/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4code_new/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4code_new/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4code_new/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4code_new/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4code_new/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4code_new/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = 'cuda'\n",
    "torch.cuda.empty_cache()\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "model = MarkdownRankModel()\n",
    "model.load_state_dict(torch.load(CODE_MARK_RANK_PATH))\n",
    "model = model.cuda()\n",
    "\n",
    "model_sigmoid = SigMoidModel().to(device)\n",
    "model_sigmoid.load_state_dict(torch.load(SIGMOID_PATH))\n",
    "model_sigmoid = model_sigmoid.cuda()\n",
    "\n",
    "model_mark_only = MarkdownOnlyModel()\n",
    "model_mark_only.load_state_dict(torch.load(MARK_PATH))\n",
    "model_mark_only = model_mark_only.cuda()\n",
    "\n",
    "# paths_test = list((DATA_DIR / 'train').glob('*.json'))[-1000:]\n",
    "# notebooks_test = [\n",
    "#     read_notebook(path) for path in tqdm(paths_test, desc='Test NBs')\n",
    "# ]\n",
    "\n",
    "# df = (\n",
    "#     pd.concat(notebooks_test)\n",
    "#     .set_index('id', append=True)\n",
    "#     .swaplevel()\n",
    "#     .sort_index(level='id', sort_remaining=False)\n",
    "# )\n",
    "\n",
    "df = pd.read_csv('data_dump/val_df.csv')\n",
    "unique_ids = pd.unique(df['id'])\n",
    "ids = unique_ids[:100]\n",
    "df = df[df['id'].isin(ids)]\n",
    "\n",
    "with open('data_dump/dict_cellid_source.pkl', 'rb') as f:\n",
    "    dict_cellid_source = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "df_orders = pd.read_csv(\n",
    "    DATA_DIR / 'train_orders.csv',\n",
    "    index_col='id',\n",
    "    squeeze=True,\n",
    ").str.split()\n",
    "\n",
    "# df.loc[df['cell_type'] == 'markdown', 'source'] = df[df['cell_type']\n",
    "#                                                      == 'markdown'].source.apply(preprocess_text)\n",
    "\n",
    "# df.loc[df['cell_type'] == 'code', 'source'] = df[df['cell_type']\n",
    "#                                                  == 'code'].source.apply(preprocess_code)\n",
    "\n",
    "dict_cellid_source = dict(\n",
    "    zip(df['cell_id'].values, df['source'].values))\n",
    "\n",
    "df[\"rank\"] = df.groupby([\"id\", \"cell_type\"]).cumcount()\n",
    "df = df.sort_values('rank').reset_index(drop=True)\n",
    "df[\"pct_rank\"] = df[\"rank\"] / \\\n",
    "    df.groupby(\"id\")[\"cell_id\"].transform(\"count\")\n",
    "\n",
    "val_fts, _, _ = get_features_rank(df, 'test')\n",
    "val_fts_only = get_features_mark(df, 'test')\n",
    "\n",
    "val_ds = SigMoidDataset(dict_cellid_source, md_max_len=MD_MAX_LEN,\n",
    "                        total_max_len=512, fts=val_fts)\n",
    "val_ds_only = MarkdownOnlyDataset(val_fts_only, dict_cellid_source, 128)\n",
    "\n",
    "val_loader = DataLoader(val_ds, batch_size=BS * 8, shuffle=False, num_workers=NW,\n",
    "                        pin_memory=False, drop_last=False)\n",
    "val_loader_only = DataLoader(val_ds_only, batch_size=BS, shuffle=False, num_workers=NW,\n",
    "                             pin_memory=False, drop_last=False)\n",
    "\n",
    "acc, true, false, relative, _, _ = validate_sigmoid(\n",
    "    model_sigmoid, val_loader, device, 0.397705)\n",
    "mark_dict = validate_markdown(model_mark_only, val_loader_only, device)\n",
    "\n",
    "# class_fts = []\n",
    "# one_object = {}\n",
    "# mark_id_dict = {}\n",
    "# for i in range(len(relative)):\n",
    "#     if relative[i] == 1:\n",
    "#         class_fts.append(val_fts[i])\n",
    "#         if val_fts[i]['mark'] not in one_object:\n",
    "#             one_object[val_fts[i]['mark']] = 1\n",
    "#         else:\n",
    "#             del one_object[val_fts[i]['mark']]\n",
    "\n",
    "# for ft in val_fts:\n",
    "#     if ft['mark'] not in one_object:\n",
    "#         mark_id_dict[ft['mark']] = mark_dict[ft['mark']] * \\\n",
    "#             (ft['total_code'] + ft['total_md'])\n",
    "\n",
    "# val_ds = MarkdownRankNewDataset(dict_cellid_source, md_max_len=MD_MAX_LEN,\n",
    "#                                 total_max_len=512, fts=class_fts)\n",
    "# val_loader = DataLoader(val_ds, batch_size=BS * 8, shuffle=False, num_workers=NW,\n",
    "#                         pin_memory=False, drop_last=False)\n",
    "\n",
    "\n",
    "y_pred, _, _ = validate_rank(model, val_loader, device)\n",
    "score = cal_kendall_tau_rank(df, y_pred, mark_dict, relative, df_orders)\n",
    "\n",
    "print('score ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threhold = 0\n",
    "# max_score = 0\n",
    "# for i in np.arange(0.249, 1, 0.001):\n",
    "#     new_relative = (relative >= i).astype(np.int8)\n",
    "#     score = cal_kendall_tau_rank(df, y_pred, None, new_relative, df_orders)\n",
    "#     if score > max_score:\n",
    "#         max_score = score\n",
    "#         threhold = i\n",
    "#     print(i, score)\n",
    "\n",
    "# print('========================================')\n",
    "# print(threhold, max_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ai4code_new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "360d45463c6cb6b732bb0bfa29da53a9e6ed32c27f9fad1b14c8f5628a173e8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
